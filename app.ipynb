{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM45zhM4lDVnSqohzhH+iVd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjdaz84pWxcg"
      },
      "outputs": [],
      "source": [
        "#edits from Gemini\n",
        "# ==============================================================================\n",
        "# 1. IMPORTS\n",
        "# ==============================================================================\n",
        "import os\n",
        "import io\n",
        "import base64\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import dash\n",
        "from dash import Dash, html, dcc, Input, Output, State, ALL, callback_context\n",
        "from dash.exceptions import PreventUpdate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CONFIGURATION & DATA LOADING\n",
        "# ==============================================================================\n",
        "# --- Configuration ---\n",
        "GCS_BUCKET_NAME = os.environ.get('GCS_BUCKET_NAME', 'solar_system_bucket')\n",
        "\n",
        "# --- Load Data from Google Cloud Storage ---\n",
        "# This section runs once when the app starts up.\n",
        "try:\n",
        "    print(\"Loading data from GCS...\")\n",
        "    base_path = f'gs://{GCS_BUCKET_NAME}'\n",
        "\n",
        "    three_month_spearman_lagged_correlations = pd.read_csv(f'{base_path}/three_month_spearman_lagged_correlation.csv', index_col=0)\n",
        "    six_month_spearman_lagged_correlations = pd.read_csv(f'{base_path}/six_month_spearman_lagged_correlation.csv', index_col=0)\n",
        "    screener_data_df = pd.read_csv(f'{base_path}/screener_data_df.csv')\n",
        "    gravitational_impact_df = pd.read_csv(f'{base_path}/gravitational_impact_df.csv')\n",
        "\n",
        "    print(\"Successfully loaded all dataframes.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"CRITICAL ERROR: Failed to load data from GCS. App may not function. Error: {e}\")\n",
        "    # Create empty dataframes so the app doesn't crash on startup\n",
        "    three_month_spearman_lagged_correlations = pd.DataFrame()\n",
        "    six_month_spearman_lagged_correlations = pd.DataFrame()\n",
        "    screener_data_df = pd.DataFrame()\n",
        "    gravitational_impact_df = pd.DataFrame()\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. DASH APP INITIALIZATION\n",
        "# ==============================================================================\n",
        "# Create a data URI for the CSS to remove body margin/padding. This avoids using html.Style which may cause issues in some environments.\n",
        "css_data_uri = 'data:text/css,body%7Bmargin:0;padding:0%7D'\n",
        "\n",
        "app = Dash(\n",
        "    __name__,\n",
        "    external_stylesheets=[\n",
        "        'https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;700&display=swap',\n",
        "        css_data_uri\n",
        "    ],\n",
        "    title='Financial Observatory',\n",
        "    suppress_callback_exceptions=True\n",
        ")\n",
        "server = app.server # Expose the Flask server for Gunicorn to run\n",
        "\n",
        "# To set the favicon (the little icon in the browser tab), create an 'assets' folder\n",
        "# in the same directory as this script and place your logo file (e.g., 'favicon.ico') inside it.\n",
        "# Dash will automatically detect and use it.\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. HELPER FUNCTIONS & LOGIC\n",
        "# ==============================================================================\n",
        "#Solar System Parameters\n",
        "min_nodes = 5\n",
        "max_nodes = 30\n",
        "threshold_percent = 0.9\n",
        "\n",
        "def process_and_score_stocks(\n",
        "    six_month_correlations,\n",
        "    three_month_correlations,\n",
        "    screener_data_df,\n",
        "    source_ticker,\n",
        "    min_nodes,\n",
        "    max_nodes,\n",
        "    threshold_percent\n",
        "):\n",
        "    \"\"\"\n",
        "    Processes stock correlation data for a specific source ticker.\n",
        "    It filters for positive correlations, computes a dynamic impact score (gravitational_force),\n",
        "    filters connections, and then calculates a final net gravitational force and the\n",
        "    maximum potential force under ideal conditions.\n",
        "\n",
        "    Args:\n",
        "      six_month_correlations: The six-month spearman lagged correlation matrix.\n",
        "      three_month_correlations: The three-month spearman lagged correlation matrix.\n",
        "      screener_data_df: DataFrame with additional stock information.\n",
        "      source_ticker: The ticker symbol for which to process data.\n",
        "      min_nodes: Minimum number of correlated stocks to return.\n",
        "      max_nodes: Maximum number of correlated stocks to return.\n",
        "      threshold_percent: A percentage (0.0 to 1.0) of the maximum force to use as a filter.\n",
        "\n",
        "    Returns:\n",
        "      processed_data_df: A pandas DataFrame with processed data for visualization.\n",
        "      source_data_df: A pandas DataFrame containing the net_gravitational_force,\n",
        "                      max_potential_force, and gravitational_impact for the source ticker,\n",
        "                      along with the source ticker's market cap influence and source_planet_radius.\n",
        "    \"\"\"\n",
        "    # --- Data Unpivoting and Initial Setup ---\n",
        "    # Start with the 6-month correlation data as the base\n",
        "    correlation_df = six_month_correlations.rename_axis('source', axis=0)\n",
        "    grouped_correlation_data = correlation_df.stack().reset_index()\n",
        "    grouped_correlation_data.columns = ['source', 'target', 'six_month_spearman_correlation']\n",
        "\n",
        "    grouped_correlation_data = grouped_correlation_data[\n",
        "        (grouped_correlation_data['source'] != grouped_correlation_data['target']) &\n",
        "        (grouped_correlation_data['target'] != source_ticker)\n",
        "    ].copy()\n",
        "\n",
        "    # --- Filter for the specific source ticker ---\n",
        "    source_connections = grouped_correlation_data[grouped_correlation_data['source'] == source_ticker].copy()\n",
        "    if source_connections.empty:\n",
        "        print(f\"No correlation data found for source ticker {source_ticker}.\")\n",
        "        # Return empty dataframes when no data is found\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    # Add 3-month correlation data before filtering\n",
        "    source_connections['three_month_spearman_correlation'] = source_connections.apply(\n",
        "        lambda row: three_month_correlations.loc[row['source'], row['target']] if row['source'] in three_month_correlations.index and row['target'] in three_month_correlations.columns else 0, axis=1\n",
        "    )\n",
        "\n",
        "    # We only care about positively correlated stocks for this model in both 6 and 3 month periods\n",
        "    positive_corr_group = source_connections[\n",
        "        (source_connections['six_month_spearman_correlation'] > 0) &\n",
        "        (source_connections['three_month_spearman_correlation'] > 0)\n",
        "    ].copy()\n",
        "\n",
        "    if positive_corr_group.empty:\n",
        "        print(f\"No positive correlations found for source ticker {source_ticker}.\")\n",
        "        # Return empty dataframes when no data is found\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    # --- Enrich Data (before filtering) ---\n",
        "    # Add market data\n",
        "    screener_cols_to_add = ['code', 'market_capitalization', 'last_day_change']\n",
        "    required_screener_cols = ['code', 'market_capitalization', 'last_day_change']\n",
        "    if not all(col in screener_data_df.columns for col in required_screener_cols):\n",
        "        missing = [col for col in required_screener_cols if col not in screener_data_df.columns]\n",
        "        raise ValueError(f\"screener_data_df is missing required columns: {missing}\")\n",
        "\n",
        "    screener_info = screener_data_df[screener_cols_to_add].rename(columns={'code': 'target'})\n",
        "    positive_corr_group = pd.merge(positive_corr_group, screener_info, on='target', how='left')\n",
        "    positive_corr_group.dropna(subset=['market_capitalization', 'last_day_change'], inplace=True)\n",
        "    if positive_corr_group.empty:\n",
        "        print(f\"No valid connections after merging screener data for {source_ticker}.\")\n",
        "        # Return empty dataframes when no data is found\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "\n",
        "    # --- Calculate Dynamic Impact Score (Gravitational Force) ---\n",
        "    epsilon = 1e-9 # Small value to avoid log(0) issues.\n",
        "    # Weights for recency bias\n",
        "    w_3m = 0.6\n",
        "    w_6m = 0.4\n",
        "    # \"unified_correlation\" is a weighted average of recent correlations.\n",
        "    positive_corr_group['unified_correlation'] = (\n",
        "        w_3m * positive_corr_group['three_month_spearman_correlation'] +\n",
        "        w_6m * positive_corr_group['six_month_spearman_correlation']\n",
        "    )\n",
        "\n",
        "    # Calculate a market cap influence score scaled between 0 and 1 for target stocks.\n",
        "    positive_corr_group['Market Cap'] = positive_corr_group['market_capitalization']\n",
        "\n",
        "    # --- Calculate source ticker's market cap and log cap ---\n",
        "    source_screener_info = screener_data_df[screener_data_df['code'] == source_ticker]\n",
        "    source_market_cap = source_screener_info['market_capitalization'].iloc[0] if not source_screener_info.empty and 'market_capitalization' in source_screener_info.columns else epsilon\n",
        "    source_log_cap = np.log(max(source_market_cap, epsilon))\n",
        "\n",
        "\n",
        "    # Calculate log market caps for all relevant tickers (source and targets)\n",
        "    all_market_caps = positive_corr_group['Market Cap'].tolist()\n",
        "    all_market_caps.append(source_market_cap) # Include source market cap\n",
        "\n",
        "    log_caps = np.log(pd.Series(all_market_caps).clip(lower=epsilon))\n",
        "\n",
        "    min_log_cap, max_log_cap = log_caps.min(), log_caps.max()\n",
        "    log_cap_range = max_log_cap - min_log_cap\n",
        "\n",
        "    # Calculate market cap influence for target stocks\n",
        "    if log_cap_range > 0:\n",
        "        positive_corr_group['market_cap_influence'] = np.log(positive_corr_group['Market Cap'].clip(lower=epsilon))\n",
        "    else:\n",
        "        positive_corr_group['market_cap_influence'] = 20 # Neutral value if all caps are the same\n",
        "\n",
        "\n",
        "    # The `gravitational_force` is a product of recent correlation strength and market influence.\n",
        "    # Modified: Increased the influence of unified_correlation by multiplying by a factor\n",
        "    correlation_weight_factor = 1.0 # Factor to increase the influence of unified_correlation\n",
        "    positive_corr_group['gravitational_force'] = (\n",
        "        (positive_corr_group['unified_correlation'] * correlation_weight_factor) * # Multiply unified_correlation by a factor\n",
        "        positive_corr_group['market_cap_influence']\n",
        "    )\n",
        "\n",
        "    # --- Apply Filtering ---\n",
        "    max_abs_force = positive_corr_group['gravitational_force'].abs().max()\n",
        "    if pd.isna(max_abs_force) or max_abs_force == 0:\n",
        "        # Return empty dataframes when no data is found\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    force_threshold = max_abs_force * threshold_percent\n",
        "    filtered_by_force_threshold = positive_corr_group[positive_corr_group['gravitational_force'].abs() >= force_threshold].copy()\n",
        "\n",
        "    # Enforce min/max node constraints\n",
        "    if len(filtered_by_force_threshold) < min_nodes:\n",
        "        final_filtered_df = positive_corr_group.sort_values(by='gravitational_force', key=abs, ascending=False).head(min_nodes).copy()\n",
        "    elif len(filtered_by_force_threshold) > max_nodes:\n",
        "        final_filtered_df = filtered_by_force_threshold.sort_values(by='gravitational_force', key=abs, ascending=False).head(max_nodes).copy()\n",
        "    else:\n",
        "        final_filtered_df = filtered_by_force_threshold.copy()\n",
        "\n",
        "    if final_filtered_df.empty:\n",
        "        print(f\"No connections remained for {source_ticker} after filtering.\")\n",
        "        # Return empty dataframes when no data is found\n",
        "        return pd.DataFrame(), pd.DataFrame()\n",
        "\n",
        "    # --- Calculate Final Net Force and Visualization Parameters ---\n",
        "    final_filtered_df['Daily Change'] = final_filtered_df['last_day_change']\n",
        "\n",
        "    final_filtered_df['signed_gravitational_force'] = final_filtered_df.apply(\n",
        "        lambda row: row['gravitational_force'] if row['Daily Change'] >= 0 else -row['gravitational_force'],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    net_gravitational_force = final_filtered_df['signed_gravitational_force'].sum()\n",
        "    max_potential_force = final_filtered_df['market_cap_influence'].sum()\n",
        "\n",
        "    # --- Calculate Visualization Parameters ---\n",
        "    min_corr, max_corr = final_filtered_df['gravitational_force'].min(), final_filtered_df['gravitational_force'].max()\n",
        "    corr_range = max_corr - min_corr if max_corr > min_corr else 1.0\n",
        "    # MODIFIED: Reverse the scaling for Orbital Radius\n",
        "    if corr_range > 0:\n",
        "        final_filtered_df['Orbital Radius'] = 1 - ((final_filtered_df['gravitational_force'] - min_corr) / corr_range)\n",
        "    else:\n",
        "        final_filtered_df['Orbital Radius'] = 0.5 # Neutral value if all forces are the same\n",
        "\n",
        "    # -----Calculate Planet Radius------\n",
        "    # Combine all market caps to find the true min and max for normalization\n",
        "    all_caps = pd.concat([\n",
        "        final_filtered_df['Market Cap'],\n",
        "        pd.Series([source_market_cap]) # Make sure source_market_cap is a Series\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    # Calculate the log, clipping to avoid errors with zero\n",
        "    log_all_caps = np.log(all_caps.clip(lower=epsilon))\n",
        "\n",
        "    # Find the min and max from the complete set of data\n",
        "    min_log_cap = log_all_caps.min()\n",
        "    max_log_cap = log_all_caps.max()\n",
        "    log_cap_range = max_log_cap - min_log_cap\n",
        "\n",
        "    # Now, apply the normalization ONLY to the DataFrame's data\n",
        "    # using the min/max from the combined set\n",
        "    if log_cap_range > 0:\n",
        "        # We are calculating log on just the dataframe column now\n",
        "        log_df_caps = np.log(final_filtered_df['Market Cap'].clip(lower=epsilon))\n",
        "        final_filtered_df['Planet Radius'] = (log_df_caps - min_log_cap) / log_cap_range\n",
        "    else:\n",
        "        # If all values are the same, assign a default radius\n",
        "        final_filtered_df['Planet Radius'] = 0.5\n",
        "\n",
        "    # Calculate source_planet_radius using the same min/max log caps from the targets and source.\n",
        "    if log_cap_range > 0:\n",
        "        source_planet_radius = (source_log_cap - min_log_cap) / log_cap_range\n",
        "    else:\n",
        "        source_planet_radius = 0.5 # Neutral value if all caps are the same\n",
        "\n",
        "    # --- Final Cleanup and Column Selection ---\n",
        "    # \"gravitational_percent\" shows the relative % contribution of each stock.\n",
        "    final_filtered_df['gravitational_percent'] = (final_filtered_df['signed_gravitational_force'] / final_filtered_df['gravitational_force'].sum()) * 100\n",
        "\n",
        "    final_columns = [\n",
        "        'source', 'target', 'Daily Change', 'six_month_spearman_correlation',\n",
        "        'three_month_spearman_correlation', 'unified_correlation',\n",
        "        'Orbital Radius', 'Market Cap', 'Planet Radius', 'market_cap_influence',\n",
        "        'gravitational_force', 'signed_gravitational_force', 'gravitational_percent'\n",
        "    ]\n",
        "\n",
        "\n",
        "    gravitational_impact = (net_gravitational_force / max_potential_force) * 100 if max_potential_force > 0 else 0\n",
        "\n",
        "    # Use the same min_log_cap and log_cap_range from target stocks for scaling\n",
        "    source_market_cap_influence = 20 if log_cap_range <= 0 else (source_log_cap)\n",
        "\n",
        "    # Create source_data_df\n",
        "    source_data_df = pd.DataFrame([{\n",
        "        'ticker': source_ticker,\n",
        "        'net_gravitational_force': net_gravitational_force,\n",
        "        'max_potential_force': max_potential_force,\n",
        "        'gravitational_impact': gravitational_impact,\n",
        "        'source_market_cap_influence': source_market_cap_influence, # Add the source influence\n",
        "        'source_planet_radius': source_planet_radius # Add the source planet radius\n",
        "    }])\n",
        "\n",
        "\n",
        "    for col in final_columns:\n",
        "        if col not in final_filtered_df.columns:\n",
        "            final_filtered_df[col] = np.nan\n",
        "\n",
        "    processed_data_df = final_filtered_df[final_columns].copy()\n",
        "\n",
        "    return processed_data_df, source_data_df\n",
        "\n",
        "def create_model_image_svg(base_color, subdivisions, texture_spots_count):\n",
        "    \"\"\"\n",
        "    Creates a base64 encoded SVG data URL that is a 2D representation of the 3D low-poly model.\n",
        "    This function generates the geometry, projects it, and simulates flat shading to match the plot.\n",
        "    \"\"\"\n",
        "    # 1. Generate the 3D model's vertices and faces for a unit sphere\n",
        "    # We pass 0 for texture_spots here because we'll draw them separately in the SVG\n",
        "    vertices, faces, _ = create_low_poly_sphere(0, 0, 0, 1, base_color, subdivisions, 0)\n",
        "\n",
        "    # 2. Define a light source for shading the facets\n",
        "    light_source = np.array([-0.5, 0.8, 1.0])\n",
        "    light_source = light_source / np.linalg.norm(light_source)\n",
        "\n",
        "    # 3. Process each face for rendering\n",
        "    face_data = []\n",
        "    for face in faces:\n",
        "        # Get the vertices for the current face\n",
        "        v0, v1, v2 = vertices[face]\n",
        "\n",
        "        # --- Back-face culling: Don't render faces pointing away from the camera ---\n",
        "        # The camera is at (0, 0, z), so we check the z-component of the normal\n",
        "        normal = np.cross(v1 - v0, v2 - v0)\n",
        "        if np.linalg.norm(normal) == 0: continue\n",
        "        normal = normal / np.linalg.norm(normal)\n",
        "        if normal[2] < 0:\n",
        "            continue # This face is on the back of the sphere, so we skip it\n",
        "\n",
        "        # --- Shading: Calculate brightness based on angle to the light source ---\n",
        "        intensity = np.dot(normal, light_source)\n",
        "        # Map intensity to a brightness factor for the color\n",
        "        color_factor = 0.65 + intensity * 0.5\n",
        "        facet_color = darken_color(base_color, color_factor)\n",
        "\n",
        "        # --- Projection: Convert 3D vertex coordinates to 2D SVG coordinates ---\n",
        "        # We scale and shift the (x, y) coordinates to fit in a 100x100 SVG\n",
        "        points_2d_str = \" \".join([f\"{(v[0] * 48) + 50},{(v[1] * -48) + 50}\" for v in [v0, v1, v2]])\n",
        "\n",
        "        # Store the face's z-depth for sorting, so closer faces draw on top\n",
        "        avg_z = (v0[2] + v1[2] + v2[2]) / 3\n",
        "        face_data.append({'z': avg_z, 'points': points_2d_str, 'color': facet_color})\n",
        "\n",
        "    # 4. Sort faces from back to front\n",
        "    face_data.sort(key=lambda f: f['z'])\n",
        "\n",
        "    # 5. Build the SVG polygons from the sorted face data\n",
        "    svg_polygons = \"\".join(f'<polygon points=\"{f[\"points\"]}\" fill=\"{f[\"color\"]}\" />' for f in face_data)\n",
        "\n",
        "    # 6. Add texture spots as random circles\n",
        "    texture_color = darken_color(base_color, 0.7)\n",
        "    svg_texture_spots = \"\"\n",
        "    np.random.seed(sum(ord(c) for c in base_color)) # Seed for consistency\n",
        "    for _ in range(texture_spots_count):\n",
        "        angle = np.random.uniform(0, 2 * np.pi)\n",
        "        radius = np.random.uniform(0, 48)\n",
        "        spot_size = np.random.uniform(4, 9)\n",
        "        cx = 50 + radius * np.cos(angle)\n",
        "        cy = 50 + radius * np.sin(angle)\n",
        "        svg_texture_spots += f'<circle cx=\"{cx}\" cy=\"{cy}\" r=\"{spot_size}\" fill=\"{texture_color}\" opacity=\"0.7\"/>'\n",
        "\n",
        "    # 7. Assemble the final SVG string\n",
        "    svg_string = f'''\n",
        "    <svg width=\"100\" height=\"100\" viewBox=\"0 0 100 100\" xmlns=\"http://www.w3.org/2000/svg\">\n",
        "      <defs>\n",
        "        <clipPath id=\"sphereClip\">\n",
        "          <circle cx=\"50\" cy=\"50\" r=\"48\"/>\n",
        "        </clipPath>\n",
        "        <filter id=\"blur-effect\">\n",
        "          <feGaussianBlur in=\"SourceGraphic\" stdDeviation=\"0.7\" />\n",
        "        </filter>\n",
        "      </defs>\n",
        "      <g clip-path=\"url(#sphereClip)\" filter=\"url(#blur-effect)\">\n",
        "        {svg_polygons}\n",
        "        {svg_texture_spots}\n",
        "      </g>\n",
        "      <circle cx=\"50\" cy=\"50\" r=\"48\" fill=\"none\" stroke=\"rgba(255, 255, 255, 0.25)\" stroke-width=\"1.5\" />\n",
        "    </svg>\n",
        "    '''\n",
        "    encoded_svg = base64.b64encode(svg_string.encode('utf-8')).decode('utf-8')\n",
        "    return f\"data:image/svg+xml;base64,{encoded_svg}\"\n",
        "\n",
        "def darken_color(color_hex, factor=0.8):\n",
        "    \"\"\"Darkens or lightens a hex color by a given factor.\"\"\"\n",
        "    rgb = mcolors.to_rgb(color_hex)\n",
        "    # Clamp values to ensure they stay within the valid [0, 1] range for RGB\n",
        "    modified_rgb = [min(max(c * factor, 0), 1) for c in rgb]\n",
        "    return mcolors.to_hex(modified_rgb)\n",
        "\n",
        "def lighten_color(color_hex, factor=0.3):\n",
        "    \"\"\"Lightens a hex color by mixing it with white.\"\"\"\n",
        "    rgb = mcolors.to_rgb(color_hex)\n",
        "    # Interpolate each component towards white (1.0)\n",
        "    modified_rgb = [c + (1 - c) * factor for c in rgb]\n",
        "    return mcolors.to_hex(modified_rgb)\n",
        "\n",
        "def create_low_poly_sphere(center_x, center_y, center_z, radius, base_color, subdivisions=2, texture_spots=15):\n",
        "    \"\"\"\n",
        "    Generates vertex and face data for a textured low-poly sphere (icosphere).\n",
        "    \"\"\"\n",
        "    # Define the 12 vertices of a regular icosahedron\n",
        "    t = (1.0 + np.sqrt(5.0)) / 2.0\n",
        "    vertices = np.array([\n",
        "        [-1,  t,  0], [ 1,  t,  0], [-1, -t,  0], [ 1, -t,  0],\n",
        "        [ 0, -1,  t], [ 0,  1,  t], [ 0, -1, -t], [ 0,  1, -t],\n",
        "        [ t,  0, -1], [ t,  0,  1], [-t,  0, -1], [-t,  0,  1]\n",
        "    ])\n",
        "\n",
        "    # Define the 20 triangular faces of the icosahedron\n",
        "    faces = np.array([\n",
        "        [0, 11, 5], [0, 5, 1], [0, 1, 7], [0, 7, 10], [0, 10, 11],\n",
        "        [1, 5, 9], [5, 11, 4], [11, 10, 2], [10, 7, 6], [7, 1, 8],\n",
        "        [3, 9, 4], [3, 4, 2], [3, 2, 6], [3, 6, 8], [3, 8, 9],\n",
        "        [4, 9, 5], [2, 4, 11], [6, 2, 10], [8, 6, 7], [9, 8, 1]\n",
        "    ])\n",
        "\n",
        "    # Subdivide faces to create more polygons\n",
        "    for _ in range(subdivisions):\n",
        "        new_faces = []\n",
        "        mid_points = {}\n",
        "        for face in faces:\n",
        "            v_indices = [face[0], face[1], face[2]]\n",
        "            new_v_indices = []\n",
        "            for i in range(3):\n",
        "                v1 = v_indices[i]\n",
        "                v2 = v_indices[(i + 1) % 3]\n",
        "                mid_key = tuple(sorted((v1, v2)))\n",
        "                mid_idx = mid_points.get(mid_key)\n",
        "                if mid_idx is None:\n",
        "                    mid_idx = len(vertices)\n",
        "                    vertices = np.vstack([vertices, (vertices[v1] + vertices[v2]) / 2.0])\n",
        "                    mid_points[mid_key] = mid_idx\n",
        "                new_v_indices.append(mid_idx)\n",
        "            new_faces.append([v_indices[0], new_v_indices[0], new_v_indices[2]])\n",
        "            new_faces.append([v_indices[1], new_v_indices[1], new_v_indices[0]])\n",
        "            new_faces.append([v_indices[2], new_v_indices[2], new_v_indices[1]])\n",
        "            new_faces.append(new_v_indices)\n",
        "        faces = np.array(new_faces)\n",
        "\n",
        "    # Normalize vertices to form a sphere, then scale and translate\n",
        "    vertices = vertices / np.linalg.norm(vertices, axis=1)[:, np.newaxis]\n",
        "    final_vertices = vertices * radius + np.array([center_x, center_y, center_z])\n",
        "\n",
        "    # Create vertex colors for texture spots\n",
        "    darker_color_hex = darken_color(base_color, 0.7)\n",
        "    vertex_colors = [base_color] * len(final_vertices)\n",
        "    if texture_spots > 0:\n",
        "        spot_indices = np.random.choice(len(final_vertices), size=texture_spots, replace=False)\n",
        "        for idx in spot_indices:\n",
        "            vertex_colors[idx] = darker_color_hex\n",
        "\n",
        "    return final_vertices, faces, vertex_colors\n",
        "\n",
        "# Updated color definitions based on user request\n",
        "RED_SPECTRUM = {'light': '#FF0000', 'dark': '#8E0000'}\n",
        "GREEN_SPECTRUM = {'light': '#1B9D49', 'dark': '#A1FF61'}\n",
        "\n",
        "red_cmap = mcolors.LinearSegmentedColormap.from_list('red_cmap', [RED_SPECTRUM['dark'], RED_SPECTRUM['light']])\n",
        "green_cmap = mcolors.LinearSegmentedColormap.from_list('green_cmap', [GREEN_SPECTRUM['light'], GREEN_SPECTRUM['dark']])\n",
        "\n",
        "def get_node_color(value, min_val, max_val):\n",
        "    \"\"\"\n",
        "    Determines the node color based on its value, using a diverging red/green scale.\n",
        "    \"\"\"\n",
        "    if value >= 0:\n",
        "        if value >= max_val:\n",
        "            return GREEN_SPECTRUM['dark']\n",
        "        norm_val = value / max_val if max_val != 0 else 0\n",
        "        return mcolors.to_hex(green_cmap(norm_val))\n",
        "    else: # value < 0\n",
        "        if value <= min_val:\n",
        "            return RED_SPECTRUM['light'] # Use light red for largest decrease\n",
        "        norm_val = abs(value / min_val) if min_val != 0 else 0\n",
        "        return mcolors.to_hex(red_cmap(norm_val))\n",
        "\n",
        "\n",
        "def solar_system_visual(source_ticker, processed_data_df, source_data_df, screener_data_df, zoom=1.5):\n",
        "    \"\"\"\n",
        "    Creates the main 3D solar system visualization with a low-poly aesthetic.\n",
        "    \"\"\"\n",
        "    ticker_connections = processed_data_df[processed_data_df['source'] == source_ticker].copy()\n",
        "    source_info_row = source_data_df[source_data_df['ticker'] == source_ticker]\n",
        "\n",
        "    if ticker_connections.empty or source_info_row.empty:\n",
        "        return go.Figure().update_layout(title=f\"Data not available for {source_ticker}\", title_x=0.5, paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', font_color='white')\n",
        "\n",
        "    source_info = source_info_row.iloc[0]\n",
        "    fig = go.Figure()\n",
        "\n",
        "    pos = {source_ticker: (0, 0, 0)}\n",
        "    actual_target_connections = ticker_connections[ticker_connections['target'] != source_ticker].copy()\n",
        "    num_connections = len(actual_target_connections)\n",
        "    radii_for_rings = []\n",
        "\n",
        "    min_visual_radius, max_visual_radius = 3.0, 10.0\n",
        "\n",
        "    if num_connections > 0:\n",
        "        original_radii = actual_target_connections['Orbital Radius']\n",
        "        min_rad, max_rad = original_radii.min(), original_radii.max()\n",
        "        rad_range = max_rad - min_rad if max_rad > min_rad else 1.0\n",
        "        visual_range = max_visual_radius - min_visual_radius\n",
        "        thetas = np.linspace(0, 2 * np.pi, num_connections, endpoint=False)\n",
        "\n",
        "        for i, (index, row) in enumerate(actual_target_connections.iterrows()):\n",
        "            scaled_radius = ((row['Orbital Radius'] - min_rad) / rad_range) * visual_range + min_visual_radius\n",
        "            radii_for_rings.append(scaled_radius)\n",
        "            theta = thetas[i]\n",
        "            pos[row['target']] = (scaled_radius * np.cos(theta), scaled_radius * np.sin(theta), 0)\n",
        "\n",
        "    # --- Add Reticle ---\n",
        "    reticle_color = 'lightgrey'\n",
        "    furthest_orbit = max(radii_for_rings) if radii_for_rings else max_visual_radius\n",
        "    reticle_length = furthest_orbit * 1.1\n",
        "    tick_length = reticle_length * 0.05\n",
        "\n",
        "    # Main lines\n",
        "    fig.add_trace(go.Scatter3d(x=[-reticle_length, reticle_length], y=[0, 0], z=[0, 0], mode='lines', line=dict(color=reticle_color, width=1), hoverinfo='none'))\n",
        "    fig.add_trace(go.Scatter3d(x=[0, 0], y=[-reticle_length, reticle_length], z=[0, 0], mode='lines', line=dict(color=reticle_color, width=1), hoverinfo='none'))\n",
        "\n",
        "    # Tick marks and labels\n",
        "    scene_annotations = []\n",
        "    tick_positions = [furthest_orbit * 0.33, furthest_orbit * 0.66, furthest_orbit]\n",
        "    # Using <br> for line breaks in the labels\n",
        "    tick_labels = [\"Most<br>Correlated\", \"Correlated\", \"Least<br>Correlated\"]\n",
        "\n",
        "    for i, pos_val in enumerate(tick_positions):\n",
        "        # Right tick\n",
        "        fig.add_trace(go.Scatter3d(x=[pos_val, pos_val], y=[-tick_length, tick_length], z=[0, 0], mode='lines', line=dict(color=reticle_color, width=1), hoverinfo='none'))\n",
        "        # Left tick\n",
        "        fig.add_trace(go.Scatter3d(x=[-pos_val, -pos_val], y=[-tick_length, tick_length], z=[0, 0], mode='lines', line=dict(color=reticle_color, width=1), hoverinfo='none'))\n",
        "        # Top tick\n",
        "        fig.add_trace(go.Scatter3d(x=[-tick_length, tick_length], y=[pos_val, pos_val], z=[0, 0], mode='lines', line=dict(color=reticle_color, width=1), hoverinfo='none'))\n",
        "        # Bottom tick\n",
        "        fig.add_trace(go.Scatter3d(x=[-tick_length, tick_length], y=[-pos_val, -pos_val], z=[0, 0], mode='lines', line=dict(color=reticle_color, width=1), hoverinfo='none'))\n",
        "\n",
        "        # Add labels on the right side, anchored to the top to appear below the line\n",
        "        scene_annotations.append(\n",
        "            dict(\n",
        "                x=pos_val, y=-(tick_length * 2), z=-0.1, # Place slightly behind and below\n",
        "                text=tick_labels[i], showarrow=False,\n",
        "                font=dict(color=reticle_color, size=10),\n",
        "                xanchor=\"center\", yanchor=\"top\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # --- Add Orbital Rings ---\n",
        "    for r in sorted(list(set(radii_for_rings))):\n",
        "        theta_ring = np.linspace(0, 2 * np.pi, 100)\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=r * np.cos(theta_ring), y=r * np.sin(theta_ring), z=np.zeros(100),\n",
        "            mode='lines',\n",
        "            line=dict(color='#454545', width=2, dash='solid'),\n",
        "            hoverinfo='none'\n",
        "        ))\n",
        "\n",
        "    # --- Loop Through Each Node to Draw Them ---\n",
        "    for node_name, coords in pos.items():\n",
        "        center_x, center_y, center_z = coords\n",
        "        is_source = (node_name == source_ticker)\n",
        "\n",
        "        screener_info_row = screener_data_df[screener_data_df['code'] == node_name]\n",
        "        if screener_info_row.empty: continue\n",
        "        screener_info = screener_info_row.iloc[0]\n",
        "\n",
        "        market_cap = screener_info.get('market_capitalization', 0)\n",
        "        market_cap_str = f\"${market_cap/1e12:.2f}T\" if market_cap > 1e12 else f\"${market_cap/1e9:.2f}B\"\n",
        "        min_visual_size, max_visual_size = 0.6, 1.5\n",
        "\n",
        "        if is_source:\n",
        "            hover_text = (f\"<b>{screener_info.get('name', node_name)} ({node_name})</b><br>\"\n",
        "                          f\"Industry: {screener_info.get('industry', 'N/A')}<br>\"\n",
        "                          f\"Sector: {screener_info.get('sector', 'N/A')}<br>\"\n",
        "                          f\"Avg Volume (1d): {screener_info.get('avgvol_1d', 'N/A')}<br>\"\n",
        "                          f\"Market Cap: {market_cap_str}\")\n",
        "            node_color = get_node_color(source_info['gravitational_impact'], -80, 80)\n",
        "            radius = min_visual_size + (source_info['source_planet_radius'] * (max_visual_size - min_visual_size))\n",
        "            subdivisions = 2\n",
        "        else:\n",
        "            processed_info = ticker_connections[ticker_connections['target'] == node_name].iloc[0]\n",
        "            hover_text = (f\"<b>{screener_info.get('name', node_name)} ({node_name})</b><br>\"\n",
        "                          f\"Industry: {screener_info.get('industry', 'N/A')}<br>\"\n",
        "                          f\"Sector: {screener_info.get('sector', 'N/A')}<br>\"\n",
        "                          f\"Avg Volume (1d): {screener_info.get('avgvol_1d', 'N/A')}<br>\"\n",
        "                          f\"Daily Change: {processed_info['Daily Change']:.2f}%<br>\"\n",
        "                          f\"Market Cap: {market_cap_str}\")\n",
        "            node_color = get_node_color(processed_info['Daily Change'], -5, 5)\n",
        "            radius = min_visual_size + (processed_info['Planet Radius'] * (max_visual_size - min_visual_size))\n",
        "            subdivisions = 2\n",
        "\n",
        "        # --- Add Aura/Atmosphere Effect ---\n",
        "        aura_fade_color = lighten_color(node_color, 0.8)\n",
        "        aura_glow_color = lighten_color(node_color, 0.4)\n",
        "\n",
        "        # Draw the outer, most transparent layer first\n",
        "        aura_fade_vertices, aura_fade_faces, _ = create_low_poly_sphere(center_x, center_y, center_z, radius * 1.08, node_color, subdivisions, 0)\n",
        "        fig.add_trace(go.Mesh3d(\n",
        "            x=aura_fade_vertices[:, 0], y=aura_fade_vertices[:, 1], z=aura_fade_vertices[:, 2],\n",
        "            i=aura_fade_faces[:, 0], j=aura_fade_faces[:, 1], k=aura_fade_faces[:, 2],\n",
        "            color=aura_fade_color, opacity=0.1, flatshading=True, hoverinfo='none'\n",
        "        ))\n",
        "\n",
        "        # Draw the middle glow layer\n",
        "        aura_glow_vertices, aura_glow_faces, _ = create_low_poly_sphere(center_x, center_y, center_z, radius * 1.05, node_color, subdivisions, 0)\n",
        "        fig.add_trace(go.Mesh3d(\n",
        "            x=aura_glow_vertices[:, 0], y=aura_glow_vertices[:, 1], z=aura_glow_vertices[:, 2],\n",
        "            i=aura_glow_faces[:, 0], j=aura_glow_faces[:, 1], k=aura_glow_faces[:, 2],\n",
        "            color=aura_glow_color, opacity=0.2, flatshading=True, hoverinfo='none'\n",
        "        ))\n",
        "\n",
        "        # --- Draw the Core Planet ---\n",
        "        vertices, faces, vertex_colors = create_low_poly_sphere(center_x, center_y, center_z, radius, node_color, subdivisions, texture_spots=15)\n",
        "        fig.add_trace(go.Mesh3d(\n",
        "            x=vertices[:, 0], y=vertices[:, 1], z=vertices[:, 2],\n",
        "            i=faces[:, 0], j=faces[:, 1], k=faces[:, 2],\n",
        "            vertexcolor=vertex_colors,\n",
        "            opacity=1.0,\n",
        "            flatshading=True,\n",
        "            lighting=dict(ambient=0.8, diffuse=0.5, specular=1, roughness=1),\n",
        "            hoverinfo='text',\n",
        "            text=hover_text,\n",
        "            hoverlabel=dict(bgcolor='#0f0524', font=dict(color='#EAEAEA', size=14), bordercolor='rgba(255, 255, 255, 0.3)')\n",
        "        ))\n",
        "\n",
        "        # Add labels for nodes\n",
        "        scene_annotations.append(\n",
        "            dict(\n",
        "                x=center_x, y=center_y, z=center_z,\n",
        "                text=f\"<b>{node_name}</b>\", showarrow=False,\n",
        "                font=dict(color='white', size=14),\n",
        "                bgcolor=\"rgba(0,0,0,0)\", xanchor=\"center\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # --- Configure Final Layout ---\n",
        "    fig.update_layout(\n",
        "        scene=dict(\n",
        "            xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False),\n",
        "            camera=dict(eye=dict(x=0, y=-1.6 * zoom, z=0.8 * zoom)), # Changed camera angle\n",
        "            aspectmode='data',\n",
        "            annotations=scene_annotations,\n",
        "            bgcolor='rgba(0,0,0,0)'\n",
        "        ),\n",
        "        margin=dict(l=0, r=0, b=0, t=0),\n",
        "        showlegend=False,\n",
        "        paper_bgcolor='rgba(0,0,0,0)',\n",
        "        plot_bgcolor='rgba(0,0,0,0)',\n",
        "        font=dict(family=\"'Space Grotesk', sans-serif\", color='#EAEAEA', size=16)\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. APP LAYOUT\n",
        "# ==============================================================================\n",
        "# --- New Theme Styles ---\n",
        "THEME = {\n",
        "    'background': '#0B041A',\n",
        "    'text': '#EAEAEA',\n",
        "    'primary': '#FFFFFF',\n",
        "    'container_bg': 'rgba(30, 15, 60, 0.3)',\n",
        "    'container_border': 'rgba(255, 255, 255, 0.1)'\n",
        "}\n",
        "\n",
        "# Starry background style\n",
        "starry_background_style = {\n",
        "    'backgroundColor': THEME['background'],\n",
        "    'backgroundImage': 'radial-gradient(circle, white 0.5px, transparent 1.5px), radial-gradient(circle, white 1px, transparent 2px), radial-gradient(circle, white 0.5px, transparent 1.5px)',\n",
        "    'backgroundSize': '350px 350px, 250px 250px, 150px 150px',\n",
        "    'backgroundPosition': '0 0, 40px 60px, 130px 270px',\n",
        "    'color': THEME['text'],\n",
        "    'fontFamily': \"'Space Grotesk', sans-serif\",\n",
        "    'minHeight': '100vh',\n",
        "    'padding': '20px'\n",
        "}\n",
        "\n",
        "font_style = {'fontFamily': \"'Space Grotesk', sans-serif\", 'color': THEME['text']}\n",
        "container_style = {\n",
        "    'backgroundColor': THEME['container_bg'],\n",
        "    'border': f\"1px solid {THEME['container_border']}\",\n",
        "    'padding': '25px 30px',\n",
        "    'borderRadius': '12px',\n",
        "    'backdropFilter': 'blur(10px)',\n",
        "    'width': '100%',\n",
        "    'boxSizing': 'border-box'\n",
        "}\n",
        "header_style = {**font_style, 'color': THEME['text'], 'textAlign': 'center', 'fontWeight': 'bold', 'marginTop': 0, 'marginBottom': '20px', 'fontSize': '22px'}\n",
        "\n",
        "# Prepare dropdown options\n",
        "# Add a check to ensure screener_data_df is not empty before creating options\n",
        "if not screener_data_df.empty:\n",
        "    ticker_options = [{'label': row['name'] + f\" ({row['code']})\", 'value': row['code']} for index, row in screener_data_df.iterrows()]\n",
        "    default_ticker = 'AAPL' if 'AAPL' in screener_data_df['code'].values else screener_data_df['code'].iloc[0]\n",
        "else:\n",
        "    ticker_options = []\n",
        "    default_ticker = None\n",
        "\n",
        "\n",
        "# Sort by gravitational_impact in descending order for top positive impacts\n",
        "top_positive_impacts = gravitational_impact_df.sort_values(by='gravitational_impact', ascending=False).head(10).reset_index(drop=True)\n",
        "# Sort by gravitational_impact in ascending order for top negative impacts\n",
        "top_negative_impacts = gravitational_impact_df.sort_values(by='gravitational_impact', ascending=True).head(10).reset_index(drop=True)\n",
        "\n",
        "# --- App Layout Definition ---\n",
        "LOGO_URL = \"https://storage.googleapis.com/financial_observatory_public/assets/Logo_rectangle.PNG\"\n",
        "\n",
        "app.layout = html.Div(style=starry_background_style, children=[\n",
        "    dcc.Store(id='zoom-level-store', data=1.5),\n",
        "    dcc.Store(id='processed-data-store'),\n",
        "    dcc.Store(id='source-data-store'),\n",
        "\n",
        "    # --- Header with Logo and Title ---\n",
        "    html.Div([\n",
        "        html.Img(src=LOGO_URL, style={'height': '50px', 'marginRight': '20px'}),\n",
        "        html.H1([\"THE FINANCIAL\", html.Br(), \"OBSERVATORY\"], style={**font_style, 'fontSize': '28px', 'fontWeight': 'bold', 'letterSpacing': '4px', 'margin': '0', 'lineHeight': '1.1'})\n",
        "    ], style={'display': 'flex', 'alignItems': 'center', 'justifyContent': 'center', 'padding': '20px 0'}),\n",
        "\n",
        "    html.Div([\n",
        "        html.P(\"Search for companies or symbols:\", style={'fontSize': 'small', 'color': 'white', 'textAlign': 'center', 'marginBottom': '5px'}),\n",
        "        dcc.Dropdown(id='ticker-dropdown', options=ticker_options, value=default_ticker, clearable=False, style={'height': '40px', 'color': 'black'})\n",
        "    ], style={'width': '90%', 'maxWidth': '500px', 'margin': '0 auto 20px auto', 'backgroundColor': THEME['container_bg'], 'border': f\"1px solid {THEME['container_border']}\", 'borderRadius': '12px', 'backdropFilter': 'blur(10px)', 'padding': '5px'}),\n",
        "\n",
        "    html.P(id='prediction-summary-text', style={'textAlign': 'center', 'padding': '10px 0', 'fontSize': '18px', 'color': THEME['text']}),\n",
        "\n",
        "    html.Div(id='graph-container', style={'height': '50vh', 'width': '98%', 'margin': 'auto', 'borderRadius': '15px', 'boxShadow': '0 0 25px 5px rgba(255, 255, 255, 0.15)'}),\n",
        "\n",
        "    html.Div(id='info-panels-container') # The main callback will now populate this\n",
        "])\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. CALLBACKS\n",
        "# ==============================================================================\n",
        "\n",
        "@app.callback(\n",
        "    [Output('info-panels-container', 'children'),\n",
        "     Output('prediction-summary-text', 'children'),\n",
        "     Output('graph-container', 'children'),\n",
        "     Output('processed-data-store', 'data'),\n",
        "     Output('source-data-store', 'data')],\n",
        "    [Input('ticker-dropdown', 'value')],\n",
        "    [State('zoom-level-store', 'data')]\n",
        ")\n",
        "def update_on_ticker_change(selected_ticker, zoom_level):\n",
        "\n",
        "    if not selected_ticker:\n",
        "        raise PreventUpdate\n",
        "\n",
        "    processed_data_df, source_data_df = process_and_score_stocks(\n",
        "        six_month_spearman_lagged_correlations, three_month_spearman_lagged_correlations, screener_data_df,\n",
        "        selected_ticker, min_nodes, max_nodes, threshold_percent\n",
        "    )\n",
        "\n",
        "    if processed_data_df.empty or source_data_df.empty:\n",
        "        empty_fig = go.Figure().update_layout(title=f\"Data not available for {selected_ticker}\", title_x=0.5, paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', font_color='white')\n",
        "        empty_graph = dcc.Graph(id='network-graph', figure=empty_fig, style={'height': '100%'})\n",
        "        no_data_msg = html.Div(f\"Data not available for {selected_ticker}\", style={'textAlign': 'center', 'padding': '20px'})\n",
        "        return no_data_msg, \"\", empty_graph, None, None\n",
        "\n",
        "    graph = dcc.Graph(id='network-graph', figure=solar_system_visual(selected_ticker, processed_data_df, source_data_df, screener_data_df, zoom_level), style={'height': '100%'})\n",
        "\n",
        "    # --- Generate data for panels and summary text ---\n",
        "    is_weekend = datetime.today().weekday() >= 5\n",
        "    star_info_screener = screener_data_df[screener_data_df['code'] == selected_ticker].iloc[0]\n",
        "    star_info_source = source_data_df[source_data_df['ticker'] == selected_ticker].iloc[0]\n",
        "    grav_impact = star_info_source.get('gravitational_impact', 0)\n",
        "    net_grav_force = star_info_source.get('net_gravitational_force', 0)\n",
        "    max_potential_force = star_info_source.get('max_potential_force', 0)\n",
        "    planets_df = processed_data_df[processed_data_df['source'] == selected_ticker].copy()\n",
        "    prediction_day_text = \"on Monday\" if is_weekend else \"today\"\n",
        "    daily_change_header = [\"Friday's\", html.Br(), \"Daily Close\"] if is_weekend else [\"Yesterday's\", html.Br(), \"Daily Change\"]\n",
        "    predictions_header_text = \"Monday's Top Predictions\" if is_weekend else \"Top Predictions\"\n",
        "    source_name = star_info_screener.get('name', selected_ticker)\n",
        "    direction = \"increase\" if grav_impact >= 0 else \"decrease\"\n",
        "    prediction_summary = f\"{source_name} ({selected_ticker}) is predicted to {direction} {prediction_day_text} with a prediction strength of {grav_impact:.2f}%.\"\n",
        "    star_color = get_node_color(grav_impact, -80, 80)\n",
        "    star_image_src = create_model_image_svg(star_color, 2, 10)\n",
        "    star_text_content = html.Div([html.P(f\"{source_name} ({selected_ticker}) is expected to {direction} {prediction_day_text} with a prediction strength of {grav_impact:.2f}%. The prediction strength is calculated based on how correlated stocks are with the next day performance of {source_name} ({selected_ticker}).\"), html.P(f\"If all of the planets in the solar system had perfect correlations, the maximum gravitational force that could exist in the system would be {max_potential_force:.2f}. The net gravitational force acting on the star right now is {net_grav_force:.2f}.\", style={'marginTop':'10px'})], style={'maxHeight':'160px','overflowY':'auto','paddingRight':'15px','maskImage':'linear-gradient(to bottom, black 80%, transparent 100%)','WebkitMaskImage':'linear-gradient(to bottom, black 80%, transparent 100%)'})\n",
        "\n",
        "    star_info_panel = html.Div([\n",
        "        html.H3(\"Star Information\",style=header_style),\n",
        "        html.Div([\n",
        "            html.Img(src=star_image_src,style={'height':'100px','width':'100px','marginRight':'20px','flexShrink':'0'}),\n",
        "            star_text_content\n",
        "        ], style={'display':'flex','alignItems':'center', 'marginBottom': '15px'}),\n",
        "        # Centered the button by wrapping it in a Div with text-align: center\n",
        "        html.Div(html.A(\n",
        "            f\" Live Data & News\",\n",
        "            href=f\"https://www.google.com/search?q=NASDAQ%3A{selected_ticker}\",\n",
        "            target=\"_blank\",\n",
        "            style={\n",
        "                'display': 'inline-flex', # Changed to inline-flex\n",
        "                'alignItems': 'center',\n",
        "                'justifyContent': 'center',\n",
        "                'padding': '8px 15px',\n",
        "                'backgroundColor': 'white',\n",
        "                'color': '#374151', # dark gray\n",
        "                'borderRadius': '9999px', # pill shape\n",
        "                'textDecoration': 'none',\n",
        "                'fontWeight': 'bold',\n",
        "                'fontSize': '16px'\n",
        "            }\n",
        "        ), style={'textAlign': 'center', 'marginTop': '20px'})\n",
        "    ],style=container_style)\n",
        "\n",
        "    prediction_items = []\n",
        "    if not top_positive_impacts.empty and not top_negative_impacts.empty:\n",
        "        combined_impacts = pd.concat([top_positive_impacts.head(5),top_negative_impacts.head(5)])\n",
        "        def create_prediction_item(row):\n",
        "            ticker, name = row['ticker'], screener_data_df[screener_data_df['code'] == row['ticker']].iloc[0]['name'] if not screener_data_df[screener_data_df['code'] == row['ticker']].empty else row['ticker']\n",
        "            return html.Div([html.Span(f\"{name} ({ticker})\"),html.Span(f\"{row['gravitational_impact']:.2f}%\",style={'color':'#4ade80' if row['gravitational_impact']>0 else '#f87171','fontWeight':'bold'})],id={'type':'prediction-item','index':ticker},n_clicks=0,style={'display':'flex','justifyContent':'space-between','padding':'8px 0','borderBottom':f'1px solid {THEME[\"container_border\"]}','cursor':'pointer'})\n",
        "        prediction_items = [create_prediction_item(row) for _,row in combined_impacts.iterrows()]\n",
        "    else: prediction_items = [html.Div(\"Top predictions not available.\")]\n",
        "    predictions_panel = html.Div([html.H3(predictions_header_text,style=header_style),html.Div(prediction_items)],style=container_style)\n",
        "\n",
        "    headers = [\"Code\",\"Name\",[\"Correlation\",html.Br(),f\"with {selected_ticker}\"],\"Market Cap\",daily_change_header,\"Grav. Force\"]\n",
        "    table_header = [html.Thead(html.Tr([html.Th(col,style={'padding':'12px','textAlign':'left','borderBottom':f\"2px solid {THEME['container_border']}\"}) for col in headers]))]\n",
        "    table_rows = []\n",
        "    if not planets_df.empty:\n",
        "        for _,p_row in planets_df.iterrows():\n",
        "            s_info = screener_data_df[screener_data_df['code'] == p_row['target']].iloc[0]\n",
        "            planet_color = get_node_color(p_row['Daily Change'], -5, 5)\n",
        "            planet_image_src = create_model_image_svg(planet_color, 2, 5)\n",
        "            ticker_cell = html.Div([html.Img(src=planet_image_src,style={'height':'40px','width':'40px','marginRight':'10px'}),html.Span(p_row['target'])],style={'display':'flex','alignItems':'center'})\n",
        "            table_rows.append(html.Tr([html.Td(ticker_cell,style={'padding':'8px 12px','borderBottom':f'1px solid {THEME[\"container_border\"]}'}),html.Td(s_info['name'],style={'padding':'8px 12px','borderBottom':f'1px solid {THEME[\"container_border\"]}'}),html.Td(f\"{p_row['unified_correlation']:.2%}\",style={'padding':'8px 12px','borderBottom':f'1px solid {THEME[\"container_border\"]}'}),html.Td(f\"${s_info['market_capitalization']/1e9:.2f}B\",style={'padding':'8px 12px','borderBottom':f'1px solid {THEME[\"container_border\"]}'}),html.Td(f\"{p_row['Daily Change']:.2f}%\",style={'padding':'8px 12px','borderBottom':f'1px solid {THEME[\"container_border\"]}'}),html.Td(f\"{p_row['signed_gravitational_force']:.2f}\",style={'padding':'8px 12px','borderBottom':f'1px solid {THEME[\"container_border\"]}'})]))\n",
        "    table_wrapper_style = {'overflowX':'auto','maskImage':'linear-gradient(to right, black 95%, transparent 100%)','WebkitMaskImage':'linear-gradient(to right, black 95%, transparent 100%)'}\n",
        "    if len(planets_df) > 5: table_wrapper_style.update({'maxHeight':'300px','overflowY':'auto'})\n",
        "    planet_table_panel = html.Div([html.H3(\"Planet Information\",style=header_style),html.Div(html.Table(table_header + [html.Tbody(table_rows)],style={'width':'100%','borderCollapse':'collapse'}),style=table_wrapper_style)],style=container_style)\n",
        "\n",
        "    # --- Control Cluster with final layout tweaks ---\n",
        "    label_column_style = {'width': '150px', 'textAlign': 'right', 'marginRight': '10px', 'fontWeight': 'bold'}\n",
        "    control_column_style = {'minWidth': '300px', 'flex': '1'}\n",
        "    twin_column_style = {'width': '150px', 'marginLeft': '10px'} # The invisible spacer\n",
        "    divider = html.Div(style={'height': '1px', 'backgroundColor': THEME['container_border'], 'margin': '12px 0'})\n",
        "    row_style = {'display': 'flex', 'alignItems': 'center', 'justifyContent': 'center'}\n",
        "\n",
        "\n",
        "    control_cluster = html.Div([\n",
        "        # Zoom Row\n",
        "        html.Div([\n",
        "            html.Div(\"Zoom:\", style=label_column_style),\n",
        "            html.Div(\n",
        "                dcc.Slider(\n",
        "                    id='zoom-slider-2',\n",
        "                    min=0.5, max=2.0, step=0.01, value=1.5,\n",
        "                    marks={0.5: {'label': 'In', 'style': {'color': 'white'}}, 1.99: {'label': 'Out', 'style': {'color': 'white'}}},\n",
        "                    className='themed-slider'\n",
        "                ),\n",
        "                style=control_column_style\n",
        "            ),\n",
        "            html.Div(style=twin_column_style)\n",
        "        ], style=row_style),\n",
        "\n",
        "        divider,\n",
        "\n",
        "        # Color Row\n",
        "        html.Div([\n",
        "            html.Div(\"Color:\", style=label_column_style),\n",
        "            html.Div([\n",
        "                html.Div(style={'height': '15px', 'borderRadius': '5px', 'background': f\"linear-gradient(to right, {RED_SPECTRUM['light']}, {RED_SPECTRUM['dark']} 49.9%, {GREEN_SPECTRUM['light']} 50.1%, {GREEN_SPECTRUM['dark']})\"}),\n",
        "                html.Div([\n",
        "                    html.Span(\"Decrease\", style={'color': 'white', 'fontSize': '12px'}),\n",
        "                    html.Span(\"Increase\", style={'color': 'white', 'fontSize': '12px'})\n",
        "                ], style={'display': 'flex', 'justifyContent': 'space-between', 'marginTop': '2px'})\n",
        "            ], style=control_column_style),\n",
        "            html.Div(style=twin_column_style)\n",
        "        ], style=row_style),\n",
        "\n",
        "        divider,\n",
        "\n",
        "        # Planet Size Text Row\n",
        "        html.Div([\n",
        "             html.Div(\"Planet Size:\", style=label_column_style),\n",
        "             html.Div(html.P(\"Based on Market Capitalization\", style={'fontSize': '14px', 'margin': '0', 'textAlign': 'left'}), style=control_column_style),\n",
        "             html.Div(style=twin_column_style)\n",
        "        ], style=row_style)\n",
        "\n",
        "    ], style={'width': '95%', 'margin': '20px auto'})\n",
        "\n",
        "\n",
        "    info_panels = html.Div([control_cluster, star_info_panel, planet_table_panel, predictions_panel], style={'display':'flex','flexDirection':'column','gap':'20px','padding':'20px 0'})\n",
        "\n",
        "    processed_data_json = processed_data_df.to_json(date_format='iso', orient='split')\n",
        "    source_data_json = source_data_df.to_json(date_format='iso', orient='split')\n",
        "\n",
        "    return info_panels, prediction_summary, graph, processed_data_json, source_data_json\n",
        "\n",
        "@app.callback(\n",
        "    Output('graph-container', 'children', allow_duplicate=True),\n",
        "    Input('zoom-slider-2', 'value'),\n",
        "    [State('ticker-dropdown', 'value'),\n",
        "     State('processed-data-store', 'data'),\n",
        "     State('source-data-store', 'data')],\n",
        "    prevent_initial_call=True\n",
        ")\n",
        "def update_graph_on_zoom(zoom_level, selected_ticker, processed_data_json, source_data_json):\n",
        "    if not all([selected_ticker, processed_data_json, source_data_json]):\n",
        "        raise PreventUpdate\n",
        "\n",
        "    processed_data_df = pd.read_json(processed_data_json, orient='split')\n",
        "    source_data_df = pd.read_json(source_data_json, orient='split')\n",
        "\n",
        "    figure = solar_system_visual(selected_ticker, processed_data_df, source_data_df, screener_data_df, zoom_level)\n",
        "    return dcc.Graph(id='network-graph', figure=figure, style={'height': '100%'})\n",
        "\n",
        "@app.callback(\n",
        "    Output('ticker-dropdown', 'value'),\n",
        "    Input({'type': 'prediction-item', 'index': ALL}, 'n_clicks'),\n",
        "    prevent_initial_call=True\n",
        ")\n",
        "def update_dropdown_from_prediction_click(n_clicks):\n",
        "    if not any(n_clicks): raise PreventUpdate\n",
        "    ctx = callback_context\n",
        "    if not ctx.triggered: raise PreventUpdate\n",
        "    triggered_id_str = ctx.triggered[0]['prop_id'].split('.')[0]\n",
        "    if not triggered_id_str: raise PreventUpdate\n",
        "    try:\n",
        "        triggered_id = json.loads(triggered_id_str)\n",
        "        new_ticker = triggered_id['index']\n",
        "        return new_ticker\n",
        "    except (json.JSONDecodeError, KeyError):\n",
        "        raise PreventUpdate\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 7. MAIN ENTRY POINT\n",
        "# ==============================================================================\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=False, host='0.0.0.0', port=8080)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 8. DockerFile\n",
        "# ==============================================================================\n",
        "# # Use the official lightweight Python image.\n",
        "# # https://hub.docker.com/_/python\n",
        "# FROM python:3.11-slim\n",
        "\n",
        "# # Allow statements and log messages to be sent straight to the logs\n",
        "# ENV PYTHONUNBUFFERED True\n",
        "\n",
        "# # Set the working directory in the container\n",
        "# WORKDIR /app\n",
        "\n",
        "# # Copy over the requirements file and install dependencies\n",
        "# COPY requirements.txt .\n",
        "# RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# # Copy the rest of your application code (app.py, etc.)\n",
        "# COPY . .\n",
        "\n",
        "# # Command to run the application using a production-grade server\n",
        "# # Gunicorn is automatically installed by the functions-framework\n",
        "# CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 --timeout 0 app:server\n",
        "# #CMD exec gunicorn --bind :$PORT --workers 1 --threads 8 --timeout 0 app_testing:server\n"
      ],
      "metadata": {
        "id": "-cF8mlO0YCWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 8. Requirements.txt\n",
        "# ==============================================================================\n",
        "\n",
        "# dash\n",
        "# pandas\n",
        "# numpy\n",
        "# matplotlib\n",
        "# scipy\n",
        "# gcsfs\n",
        "# gunicorn"
      ],
      "metadata": {
        "id": "qjr1BNL0YEni"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}