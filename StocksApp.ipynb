{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "qPom_aYMeUSx",
        "Nn9reOwbE96J",
        "AuEQvbbnFGfT",
        "XlkrSQJ8aSKT",
        "WjGziKSbFiNp",
        "IZGBHr-YAJ5U"
      ],
      "mount_file_id": "https://github.com/Risskr/Stock-App/blob/main/StocksApp.ipynb",
      "authorship_tag": "ABX9TyMGYzdNxHMAgMPCO6f50l6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Risskr/Stock-App/blob/Simplified/StocksApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set Up**\n"
      ],
      "metadata": {
        "id": "qPom_aYMeUSx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqHgaNKkh5iP",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e120bc1-6feb-4f7d-ef0e-df0ff96cbff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cudf.pandas extension is already loaded. To reload it, use:\n",
            "  %reload_ext cudf.pandas\n"
          ]
        }
      ],
      "source": [
        "# #refesh python script\n",
        "# get_ipython().kernel.do_shutdown(restart=True)\n",
        "\n",
        "# #Check GPUs\n",
        "# !nvidia-smi\n",
        "\n",
        "#load cudf to use GPUs for analysis\n",
        "%load_ext cudf.pandas\n",
        "\n",
        "# import pandas\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Examples**"
      ],
      "metadata": {
        "id": "pB5S7lY7ODCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example how to locate in dataframes and in sereies"
      ],
      "metadata": {
        "id": "XlkrSQJ8aSKT"
      }
    },
    {
      "source": [
        "# GOOGDailyClose_Series = GOOGDailyClose['close']\n",
        "\n",
        "# x = GOOGDailyClose.loc[('GOOG', 2020, 1, 2), 'close']\n",
        "# print(x)\n",
        "\n",
        "# y = GOOGDailyClose_Series.loc[('GOOG', 2020, 1, 2)]\n",
        "# print(y)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "EAJJI4s9PtYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example graph"
      ],
      "metadata": {
        "id": "WjGziKSbFiNp"
      }
    },
    {
      "source": [
        "# # from matplotlib import pyplot as plt\n",
        "# # GOOGDailyClose['close'].plot(kind='line', figsize=(8, 4), title='close')\n",
        "# # plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# # Create the plot for GOOGDailyClose\n",
        "# ax = GOOGDailyClose['close'].plot(kind='line', figsize=(8, 4), title='Closing Stock Prices')\n",
        "\n",
        "# # Add the plot for MSFTDailyClose to the same axes\n",
        "# MSFTDailyClose['close'].plot(kind='line', ax=ax)\n",
        "\n",
        "# # Hide the top and right spines\n",
        "# plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "\n",
        "# # Add a legend to distinguish the lines\n",
        "# plt.legend(['GOOG', 'MSFT'])"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "OPyPXSyWqeD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Call Function from another file\n",
        "Eample Call Correlation_Coefficient function from another My Drive file"
      ],
      "metadata": {
        "id": "IZGBHr-YAJ5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %run \"/content/drive/My Drive/Colab Notebooks/Correlation_Coefficient.ipynb\"\n",
        "\n",
        "# Correlation_Coefficient(GOOGDailyClose, MSFTDaily Close)\n"
      ],
      "metadata": {
        "id": "7rhY5LPO7oHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Input Variable from MY Drive\n"
      ],
      "metadata": {
        "id": "iN_ryqgvnFM6"
      }
    },
    {
      "source": [
        "import pickle\n",
        "\n",
        "# Define the path where you saved the file\n",
        "load_path = \"/content/drive/MyDrive/Colab Notebooks/all_correlations.pkl\"\n",
        "\n",
        "try:\n",
        "    # Open the file in binary read mode ('rb')\n",
        "    with open(load_path, 'rb') as f:\n",
        "        # Use pickle.load() to deserialize and load the dictionary\n",
        "        loaded_correlations = pickle.load(f)\n",
        "\n",
        "    print(f\"Successfully loaded data from {load_path}\")\n",
        "\n",
        "    # You can now use the loaded_correlations dictionary\n",
        "    # print(loaded_correlations.keys()) # Example: print the keys to verify\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file was not found at {load_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziAUfSzymzUc",
        "outputId": "a10b7270-a9b9-4192-d8e9-aba1121e6946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data from /content/drive/MyDrive/Colab Notebooks/all_correlations.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Export variable to My Drive"
      ],
      "metadata": {
        "id": "EYLv8nAunJdW"
      }
    },
    {
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# Define the path to save the file in your Google Drive\n",
        "# Make sure you have mounted your Google Drive\n",
        "# For example, if your Drive is mounted at /content/drive,\n",
        "# you can save it in a folder like 'Colab Notebooks'\n",
        "save_path = \"/content/drive/MyDrive/Colab Notebooks/all_correlations.pkl\"\n",
        "\n",
        "# Ensure the directory exists if you are saving to a subfolder\n",
        "# if not os.path.exists(os.path.dirname(save_path)):\n",
        "#     os.makedirs(os.path.dirname(save_path))\n",
        "\n",
        "try:\n",
        "    # Open the file in binary write mode ('wb')\n",
        "    with open(save_path, 'wb') as f:\n",
        "        # Use pickle.dump() to serialize and save the dictionary\n",
        "        pickle.dump(all_correlations_with_info, f)\n",
        "\n",
        "    print(f\"Successfully saved all_correlations_with_info to {save_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the file: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfVjRhSjmq94",
        "outputId": "094a983f-7bab-47a5-ba05-d5afb7954415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved all_correlations_with_info to /content/drive/MyDrive/Colab Notebooks/all_correlations.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get Stock Data**"
      ],
      "metadata": {
        "id": "xe0ltjSPehDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Download Stock Data to My Drive"
      ],
      "metadata": {
        "id": "Nn9reOwbE96J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DownloadStockData():\n",
        "  #Download the stock data\n",
        "  !if [ ! -f \"usa_stocks_30m.parquet\" ]; then curl https://storage.googleapis.com/rapidsai/colab-data/usa_stocks_30m.parquet -o usa_stocks_30m.parquet; else echo \"usa_stocks_30m.parquet found\"; fi\n",
        "\n",
        "  #move the stock data to my Drive\n",
        "  !mv usa_stocks_30m.parquet \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "metadata": {
        "id": "2ipu4MZZV3_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Import Stock Data from My Drive"
      ],
      "metadata": {
        "id": "AuEQvbbnFGfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ImportStockData():\n",
        "  # Import the stock data from My Drive\n",
        "  # Define nasdaq_stocks as the stock data\n",
        "  # Specify the full path to the file in your Google Drive\n",
        "  nasdaq_stocks = pd.read_parquet(\"/content/drive/MyDrive/Colab Notebooks/usa_stocks_30m.parquet\")\n",
        "  return nasdaq_stocks\n"
      ],
      "metadata": {
        "id": "U-s77lCvT7rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Manipulate raw stock data for correlation funciton"
      ],
      "metadata": {
        "id": "VTUSJsRLFNcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ManipulateStockData(nasdaq_stocks):\n",
        "  #add year, month, and day columns\n",
        "  #df[[\"year\", \"week\", \"day\"]] = df.datetime.dt.isocalendar()\n",
        "  nasdaq_stocks[\"year\"] = nasdaq_stocks.datetime.dt.year\n",
        "  nasdaq_stocks[\"month\"] = nasdaq_stocks.datetime.dt.month\n",
        "  nasdaq_stocks[\"day\"] = nasdaq_stocks.datetime.dt.day\n",
        "\n",
        "  # Filter the DataFrame based on the 'year' column\n",
        "  stock_TimeFiltered = nasdaq_stocks.loc[nasdaq_stocks['year'] >= 2023]\n",
        "\n",
        "  #stock_TimeFiltered.info()\n",
        "  #stock_TimeFiltered.head()\n",
        "\n",
        "  #aggregate data by ticker, month, day, closing cost.\n",
        "  stock_TimeFiltered_aggregated_close = stock_TimeFiltered.groupby([\"ticker\", \"year\", \"month\", \"day\"]).agg({\"close\": \"last\"})\n",
        "\n",
        "  #stock_TimeFiltered_aggregated_close.info()\n",
        "  #stock_TimeFiltered_aggregated_close.head()\n",
        "  return stock_TimeFiltered_aggregated_close"
      ],
      "metadata": {
        "id": "Gl82QadwUTHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation Coefficent funtions**"
      ],
      "metadata": {
        "id": "Yx4PfQYuNsi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Coeficient on entire stock data set"
      ],
      "metadata": {
        "id": "FVS3pKjwNkQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Correlation_Coefficient with Lag"
      ],
      "metadata": {
        "id": "_pVCvXWUGena"
      }
    },
    {
      "source": [
        "# Correlation_Coefficient Function with Lag\n",
        "# Using the Pearson correlation coefficient to determine correlation between two stocks with a lag\n",
        "\n",
        "def Correlation_Coefficient_Lag(StockA, StockB, k=0):\n",
        "  # Calculate the correlation between the 'close' columns with a lag\n",
        "  StockA_series = StockA['close'].droplevel('ticker')\n",
        "  StockB_series = StockB['close'].droplevel('ticker')\n",
        "\n",
        "  # Apply the lag to StockB\n",
        "  # Shift the StockB series down by k periods.\n",
        "  # Positive k shifts data points forward, filling early entries with NaN.\n",
        "  # Negative k shifts data points backward, filling late entries with NaN.\n",
        "  StockB_lagged = StockB_series.shift(k)\n",
        "\n",
        "  # Calculate the correlation between the original StockA and the lagged StockB\n",
        "  # The .corr() method automatically handles NaN values by excluding them\n",
        "  correlation = StockA_series.corr(StockB_lagged)\n",
        "\n",
        "  return correlation\n",
        "\n",
        "# Example usage with a lag of k=1 day\n",
        "correlation_value_lag1 = Correlation_Coefficient_Lag(GOOGDailyClose, MSFTDailyClose, k=1)\n",
        "print(f\"The Pearson correlation coefficient between GOOG and MSFT with a 1-day lag on MSFT is: {correlation_value_lag1}\")\n",
        "\n",
        "# Example usage with a lag of k=-1 day\n",
        "correlation_value_lag_neg1 = Correlation_Coefficient_Lag(GOOGDailyClose, MSFTDailyClose, k=-1)\n",
        "print(f\"The Pearson correlation coefficient between GOOG and MSFT with a -1-day lag on MSFT is: {correlation_value_lag_neg1}\")\n",
        "\n",
        "# Example usage with no lag (k=0)\n",
        "correlation_value_lag0 = Correlation_Coefficient_Lag(GOOGDailyClose, MSFTDailyClose, k=0)\n",
        "print(f\"The Pearson correlation coefficient between GOOG and MSFT with no lag is: {correlation_value_lag0}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "RaVWV0y2PKdy",
        "outputId": "76f46bdf-cec6-4507-9a6d-0056d4543b97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Pearson correlation coefficient between GOOG and MSFT with a 1-day lag on MSFT is: 0.8962704402662925\n",
            "The Pearson correlation coefficient between GOOG and MSFT with a -1-day lag on MSFT is: 0.8945621869369759\n",
            "The Pearson correlation coefficient between GOOG and MSFT with no lag is: 0.8976408107388537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Sample GOOG and MSFT Correlation"
      ],
      "metadata": {
        "id": "uK3tEpu0nyDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Def GOOG&MSFT():\n",
        "  # Access the 'ticker' level from the index for filtering\n",
        "  GOOGDailyClose = stock_TimeFiltered_aggregated_close.loc[stock_TimeFiltered_aggregated_close.index.get_level_values('ticker') == \"GOOG\"]\n",
        "  MSFTDailyClose = stock_TimeFiltered_aggregated_close.loc[stock_TimeFiltered_aggregated_close.index.get_level_values('ticker') == \"MSFT\"]\n",
        "\n",
        "  GOOGDailyClose.info()\n",
        "  GOOGDailyClose.head()\n",
        "\n",
        "# Correlation_Coefficient Function\n",
        "# Using the Pearson correlation coefficient to determine correlation between two stocks\n",
        "\n",
        "def Correlation_Coefficient_testing(StockA, StockB):\n",
        "  # Calculate the correlation between the 'close' columns\n",
        "  StockA = StockA['close'].droplevel('ticker')\n",
        "  StockB = StockB['close'].droplevel('ticker')\n",
        "  correlation = StockA.corr(StockB)\n",
        "  return correlation\n",
        "\n",
        "  correlation_value = Correlation_Coefficient_testing(GOOGDailyClose, MSFTDailyClose)\n",
        "  print(f\"The Pearson correlation coefficient between GOOG and MSFT is: {correlation_value}\")"
      ],
      "metadata": {
        "id": "nHJt6DToYIU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23762ea1-30fc-4f2a-d801-549fa5573924",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'cudf.core.dataframe.DataFrame'>\n",
            "MultiIndex: 1104 entries, ('GOOG', np.int16(2020), np.int16(1), np.int16(2)) to ('GOOG', np.int16(2024), np.int16(3), np.int16(13))\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   close   1104 non-null   float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 62.0+ KB\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def calculate_pairwise_lagged_correlation(df, end_date, lag_days=1):\n",
        "  \"\"\"\n",
        "  Calculates the pairwise Pearson correlation coefficient between all stocks\n",
        "  in a DataFrame for a specified 6-month period with a given lag.\n",
        "\n",
        "  Args:\n",
        "    df: DataFrame with a MultiIndex (ticker, year, month, day) and 'close' column.\n",
        "    end_date: The end date (inclusive) of the 6-month period as a string 'YYYY-MM-DD'.\n",
        "    lag_days: The number of days to lag the second stock's data.\n",
        "\n",
        "  Returns:\n",
        "    A pandas DataFrame containing the pairwise correlation coefficients.\n",
        "  \"\"\"\n",
        "  # Convert end_date to datetime object\n",
        "  end_datetime = pd.to_datetime(end_date)\n",
        "\n",
        "  # Calculate the start date for the 6-month period\n",
        "  start_datetime = end_datetime - pd.DateOffset(months=6)\n",
        "\n",
        "  # Filter the DataFrame for the specified date range\n",
        "  # We need to create a datetime column from the index to filter\n",
        "  df['datetime'] = pd.to_datetime(df.index.get_level_values('year').astype(str) + '-' +\n",
        "                                   df.index.get_level_values('month').astype(str) + '-' +\n",
        "                                   df.index.get_level_values('day').astype(str))\n",
        "  filtered_df = df[(df['datetime'] >= start_datetime) & (df['datetime'] <= end_datetime)]\n",
        "  filtered_df = filtered_df.drop(columns=['datetime']) # Drop the temporary datetime column\n",
        "\n",
        "  # Get unique tickers in the filtered data\n",
        "  tickers = filtered_df.index.get_level_values('ticker').unique()\n",
        "\n",
        "  # Create an empty DataFrame to store correlation results\n",
        "  correlation_matrix = pd.DataFrame(index=tickers, columns=tickers, dtype=float)\n",
        "\n",
        "  # Iterate through all pairs of tickers\n",
        "  for ticker_a in tickers:\n",
        "    for ticker_b in tickers:\n",
        "      if ticker_a != ticker_b:\n",
        "        # Extract data for each ticker\n",
        "        stock_a_data = filtered_df.loc[ticker_a, 'close']\n",
        "        stock_b_data = filtered_df.loc[ticker_b, 'close']\n",
        "\n",
        "        # Align the dataframes based on the date index\n",
        "        aligned_data = pd.merge(stock_a_data.reset_index(), stock_b_data.reset_index(),\n",
        "                                on=['year', 'month', 'day'], how='inner', suffixes=('_A', '_B'))\n",
        "        aligned_data['datetime'] = pd.to_datetime(aligned_data['year'].astype(str) + '-' +\n",
        "                                                  aligned_data['month'].astype(str) + '-' +\n",
        "                                                  aligned_data['day'].astype(str))\n",
        "        aligned_data = aligned_data.set_index('datetime').sort_index()\n",
        "\n",
        "        # Apply the lag to stock_b_data\n",
        "        lagged_stock_b_data = aligned_data['close_B'].shift(lag_days)\n",
        "\n",
        "        # Calculate correlation, dropping NaN values\n",
        "        correlation = aligned_data['close_A'].corr(lagged_stock_b_data)\n",
        "\n",
        "        # Store the correlation in the matrix\n",
        "        correlation_matrix.loc[ticker_a, ticker_b] = correlation\n",
        "\n",
        "  return correlation_matrix\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'stock_TimeFiltered_aggregated_close' is your aggregated stock data\n",
        "# and you want to calculate correlations ending on '2023-12-31' with a 1-day lag.\n",
        "# Replace 'stock_TimeFiltered_aggregated_close' with the actual name of your DataFrame.\n",
        "end_date = '2023-12-31'\n",
        "lagged_correlations = calculate_pairwise_lagged_correlation(stock_TimeFiltered_aggregated_close, end_date, lag_days=1)\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(lagged_correlations)\n",
        "\n",
        "# To access the correlation between specific stocks, e.g., GOOG and MSFT:\n",
        "# print(lagged_correlations.loc['GOOG', 'MSFT'])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "36PCpThlit7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run Fucntions**"
      ],
      "metadata": {
        "id": "aCEfO-bsKNCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nasdaq_stocks = ImportStockData()"
      ],
      "metadata": {
        "id": "BxwPwW4fKQa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_TimeFiltered_aggregated_close = ManipulateStockData(nasdaq_stocks)"
      ],
      "metadata": {
        "id": "yiDPP4LjL8dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3h82777HM302"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}