{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qPom_aYMeUSx",
        "Nn9reOwbE96J",
        "AuEQvbbnFGfT",
        "XlkrSQJ8aSKT",
        "WjGziKSbFiNp",
        "IZGBHr-YAJ5U"
      ],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/Risskr/Stock-App/blob/Simplified/StocksApp.ipynb",
      "authorship_tag": "ABX9TyMW1YMDFUVckNz5ghQS0Wtz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Risskr/Stock-App/blob/Simplified/StocksApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set Up**\n"
      ],
      "metadata": {
        "id": "qPom_aYMeUSx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NqHgaNKkh5iP",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# #refesh python script\n",
        "# get_ipython().kernel.do_shutdown(restart=True)\n",
        "\n",
        "# #Check GPUs\n",
        "# !nvidia-smi\n",
        "\n",
        "#load cudf to use GPUs for analysis\n",
        "#%load_ext cudf.pandas\n",
        "\n",
        "# import pandas\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "#!pip install tqdm==4.66.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Examples**"
      ],
      "metadata": {
        "id": "pB5S7lY7ODCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example how to locate in dataframes and in sereies"
      ],
      "metadata": {
        "id": "XlkrSQJ8aSKT"
      }
    },
    {
      "source": [
        "# GOOGDailyClose_Series = GOOGDailyClose['close']\n",
        "\n",
        "# x = GOOGDailyClose.loc[('GOOG', 2020, 1, 2), 'close']\n",
        "# print(x)\n",
        "\n",
        "# y = GOOGDailyClose_Series.loc[('GOOG', 2020, 1, 2)]\n",
        "# print(y)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "EAJJI4s9PtYV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example graph"
      ],
      "metadata": {
        "id": "WjGziKSbFiNp"
      }
    },
    {
      "source": [
        "# # from matplotlib import pyplot as plt\n",
        "# # GOOGDailyClose['close'].plot(kind='line', figsize=(8, 4), title='close')\n",
        "# # plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# # Create the plot for GOOGDailyClose\n",
        "# ax = GOOGDailyClose['close'].plot(kind='line', figsize=(8, 4), title='Closing Stock Prices')\n",
        "\n",
        "# # Add the plot for MSFTDailyClose to the same axes\n",
        "# MSFTDailyClose['close'].plot(kind='line', ax=ax)\n",
        "\n",
        "# # Hide the top and right spines\n",
        "# plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "\n",
        "# # Add a legend to distinguish the lines\n",
        "# plt.legend(['GOOG', 'MSFT'])"
      ],
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "id": "OPyPXSyWqeD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Call Function from another file\n",
        "Eample Call Correlation_Coefficient function from another My Drive file"
      ],
      "metadata": {
        "id": "IZGBHr-YAJ5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %run \"/content/drive/My Drive/Colab Notebooks/Correlation_Coefficient.ipynb\"\n",
        "\n",
        "# Correlation_Coefficient(GOOGDailyClose, MSFTDaily Close)\n"
      ],
      "metadata": {
        "id": "7rhY5LPO7oHq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get Stock Data**"
      ],
      "metadata": {
        "id": "xe0ltjSPehDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Download Stock Data to My Drive"
      ],
      "metadata": {
        "id": "Nn9reOwbE96J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DownloadStockData():\n",
        "  #Download the stock data\n",
        "  !if [ ! -f \"usa_stocks_30m.parquet\" ]; then curl https://storage.googleapis.com/rapidsai/colab-data/usa_stocks_30m.parquet -o usa_stocks_30m.parquet; else echo \"usa_stocks_30m.parquet found\"; fi\n",
        "\n",
        "  #move the stock data to my Drive\n",
        "  !mv usa_stocks_30m.parquet \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "metadata": {
        "id": "2ipu4MZZV3_y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Import Stock Data from My Drive"
      ],
      "metadata": {
        "id": "AuEQvbbnFGfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ImportStockData():\n",
        "  # Import the stock data from My Drive\n",
        "  # Define nasdaq_stocks as the stock data\n",
        "  # Specify the full path to the file in your Google Drive\n",
        "  nasdaq_stocks = pd.read_parquet(\"/content/drive/MyDrive/Colab Notebooks/usa_stocks_30m.parquet\")\n",
        "  return nasdaq_stocks\n"
      ],
      "metadata": {
        "id": "U-s77lCvT7rQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions: Export/Import variables to My Drive"
      ],
      "metadata": {
        "id": "EYLv8nAunJdW"
      }
    },
    {
      "source": [
        "def export_variable(variable_name, file_name):\n",
        "\n",
        "  now = datetime.datetime.now()\n",
        "\n",
        "  save_path = f\"/content/drive/MyDrive/Colab Notebooks/{file_name}_{now}.parquet\"\n",
        "\n",
        "  try:\n",
        "      variable_name.to_parquet(save_path)\n",
        "      print(f\"Successfully saved the variable to {save_path}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred while saving the file: {e}\")\n",
        "  return\n",
        "\n",
        "# # use this line to run the function\n",
        "# export_variable(lagged_correlations, \"lagged_correlation\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JfVjRhSjmq94"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "source": [
        "def import_variable(file_name):\n",
        "  load_path = f\"/content/drive/MyDrive/Colab Notebooks/{file_name}\"\n",
        "\n",
        "  try:\n",
        "      variable = pd.read_parquet(load_path)\n",
        "\n",
        "      print(f\"Successfully loaded data from {load_path}\")\n",
        "\n",
        "  except FileNotFoundError:\n",
        "      print(f\"Error: The file was not found at {load_path}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred while loading the file: {e}\")\n",
        "  return variable\n",
        "\n",
        "# #run this funciton with this line\n",
        "# x = import_variable(\"testing2_2025-05-22 19:07:29.595379.parquet\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ziAUfSzymzUc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Manipulate raw stock data for correlation funciton"
      ],
      "metadata": {
        "id": "VTUSJsRLFNcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ManipulateStockData(nasdaq_stocks):\n",
        "  #add year, month, and day columns\n",
        "  #df[[\"year\", \"week\", \"day\"]] = df.datetime.dt.isocalendar()\n",
        "  nasdaq_stocks[\"year\"] = nasdaq_stocks.datetime.dt.year\n",
        "  nasdaq_stocks[\"month\"] = nasdaq_stocks.datetime.dt.month\n",
        "  nasdaq_stocks[\"day\"] = nasdaq_stocks.datetime.dt.day\n",
        "\n",
        "  # Filter the DataFrame based on the 'year' column\n",
        "  stock_TimeFiltered = nasdaq_stocks.loc[nasdaq_stocks['year'] >= 2023]\n",
        "\n",
        "  #stock_TimeFiltered.info()\n",
        "  #stock_TimeFiltered.head()\n",
        "\n",
        "  #aggregate data by ticker, month, day, closing cost.\n",
        "  stock_TimeFiltered_aggregated_close = stock_TimeFiltered.groupby([\"ticker\", \"year\", \"month\", \"day\"]).agg({\"close\": \"last\"})\n",
        "\n",
        "  #stock_TimeFiltered_aggregated_close.info()\n",
        "  #stock_TimeFiltered_aggregated_close.head()\n",
        "  return stock_TimeFiltered_aggregated_close"
      ],
      "metadata": {
        "id": "Gl82QadwUTHF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation Coefficent funtions**"
      ],
      "metadata": {
        "id": "Yx4PfQYuNsi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Correlation_Coefficient with Lag for two stocks"
      ],
      "metadata": {
        "id": "_pVCvXWUGena"
      }
    },
    {
      "source": [
        "# Correlation_Coefficient Function with Lag\n",
        "# Using the Pearson correlation coefficient to determine correlation between two stocks with a lag\n",
        "\n",
        "def Correlation_Coefficient_Lag(StockA, StockB, k=0):\n",
        "  # Calculate the correlation between the 'close' columns with a lag\n",
        "  StockA_series = StockA['close'].droplevel('ticker')\n",
        "  StockB_series = StockB['close'].droplevel('ticker')\n",
        "\n",
        "  # Apply the lag to StockB\n",
        "  # Shift the StockB series down by k periods.\n",
        "  # Positive k shifts data points forward, filling early entries with NaN.\n",
        "  # Negative k shifts data points backward, filling late entries with NaN.\n",
        "  StockB_lagged = StockB_series.shift(k)\n",
        "\n",
        "  # Calculate the correlation between the original StockA and the lagged StockB\n",
        "  # The .corr() method automatically handles NaN values by excluding them\n",
        "  correlation = StockA_series.corr(StockB_lagged)\n",
        "\n",
        "  return correlation\n",
        "\n",
        "# # Example usage with a lag of k=1 day\n",
        "# correlation_value_lag1 = Correlation_Coefficient_Lag(GOOGDailyClose, MSFTDailyClose, k=1)\n",
        "# print(f\"The Pearson correlation coefficient between GOOG and MSFT with a 1-day lag on MSFT is: {correlation_value_lag1}\")\n",
        "\n",
        "# # Example usage with a lag of k=-1 day\n",
        "# correlation_value_lag_neg1 = Correlation_Coefficient_Lag(GOOGDailyClose, MSFTDailyClose, k=-1)\n",
        "# print(f\"The Pearson correlation coefficient between GOOG and MSFT with a -1-day lag on MSFT is: {correlation_value_lag_neg1}\")\n",
        "\n",
        "# # Example usage with no lag (k=0)\n",
        "# correlation_value_lag0 = Correlation_Coefficient_Lag(GOOGDailyClose, MSFTDailyClose, k=0)\n",
        "# print(f\"The Pearson correlation coefficient between GOOG and MSFT with no lag is: {correlation_value_lag0}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "RaVWV0y2PKdy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Sample GOOG and MSFT Correlation"
      ],
      "metadata": {
        "id": "uK3tEpu0nyDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GOOG&MSFT():\n",
        "  # Access the 'ticker' level from the index for filtering\n",
        "  GOOGDailyClose = stock_TimeFiltered_aggregated_close.loc[stock_TimeFiltered_aggregated_close.index.get_level_values('ticker') == \"GOOG\"]\n",
        "  MSFTDailyClose = stock_TimeFiltered_aggregated_close.loc[stock_TimeFiltered_aggregated_close.index.get_level_values('ticker') == \"MSFT\"]\n",
        "\n",
        "  GOOGDailyClose.info()\n",
        "  GOOGDailyClose.head()\n",
        "\n",
        "# Correlation_Coefficient Function\n",
        "# Using the Pearson correlation coefficient to determine correlation between two stocks\n",
        "\n",
        "def Correlation_Coefficient_testing(StockA, StockB):\n",
        "  # Calculate the correlation between the 'close' columns\n",
        "  StockA = StockA['close'].droplevel('ticker')\n",
        "  StockB = StockB['close'].droplevel('ticker')\n",
        "  correlation = StockA.corr(StockB)\n",
        "  return correlation\n",
        "\n",
        "  correlation_value = Correlation_Coefficient_testing(GOOGDailyClose, MSFTDailyClose)\n",
        "  print(f\"The Pearson correlation coefficient between GOOG and MSFT is: {correlation_value}\")"
      ],
      "metadata": {
        "id": "nHJt6DToYIU5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "11bafefd-9d07-4a60-fd8f-eaaa08fdd873",
        "collapsed": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected '(' (<ipython-input-22-23c9278c083c>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-23c9278c083c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def GOOG&MSFT():\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected '('\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function: Correlation Coeficient for entire stock data set"
      ],
      "metadata": {
        "id": "-Aj3d3SJJe3p"
      }
    },
    {
      "source": [
        "def calculate_lagged_correlation(df, end_date, lag_days=1):\n",
        "  # import pandas as pd\n",
        "  # import numpy as np\n",
        "  # from tqdm.notebook import tqdm # Import tqdm\n",
        "  \"\"\"\n",
        "  Calculates the pairwise Pearson correlation coefficient between all stocks\n",
        "  in a DataFrame for a specified 6-month period with a given lag.\n",
        "\n",
        "  Args:\n",
        "    df: DataFrame with a MultiIndex (ticker, year, month, day) and 'close' column.\n",
        "    end_date: The end date (inclusive) of the 6-month period as a string 'YYYY-MM-DD'.\n",
        "    lag_days: The number of days to lag the second stock's data.\n",
        "\n",
        "  Returns:\n",
        "    A pandas DataFrame containing the pairwise correlation coefficients.\n",
        "  \"\"\"\n",
        "  # Convert end_date to datetime object\n",
        "  end_datetime = pd.to_datetime(end_date)\n",
        "\n",
        "  # Calculate the start date for the 6-month period\n",
        "  start_datetime = end_datetime - pd.DateOffset(months=6)\n",
        "\n",
        "  # Filter the DataFrame for the specified date range\n",
        "  # We need to create a datetime column from the index to filter\n",
        "  df['datetime'] = pd.to_datetime(df.index.get_level_values('year').astype(str) + '-' +\n",
        "                                   df.index.get_level_values('month').astype(str) + '-' +\n",
        "                                   df.index.get_level_values('day').astype(str))\n",
        "  filtered_df = df[(df['datetime'] >= start_datetime) & (df['datetime'] <= end_datetime)]\n",
        "  filtered_df = filtered_df.drop(columns=['datetime']) # Drop the temporary datetime column\n",
        "\n",
        "\n",
        "  # Get unique tickers in the filtered data\n",
        "  tickers = filtered_df.index.get_level_values('ticker').unique()\n",
        "\n",
        "  # Create an empty DataFrame to store correlation results\n",
        "  correlation_matrix = pd.DataFrame(index=tickers, columns=tickers, dtype=float)\n",
        "\n",
        "  # Iterate through all pairs of tickers with a progress bar\n",
        "  for ticker_a in tqdm(tickers, desc=\"Calculating correlations\"): # Add tqdm here\n",
        "\n",
        "    # Extract data for each ticker\n",
        "    stock_a_data = filtered_df.loc[ticker_a, 'close']\n",
        "\n",
        "    for ticker_b in tickers:\n",
        "      if ticker_a != ticker_b:\n",
        "        # Extract data for each ticker\n",
        "        stock_b_data = filtered_df.loc[ticker_b, 'close']\n",
        "\n",
        "        # Align the dataframes based on the date index\n",
        "        aligned_data = pd.merge(stock_a_data.reset_index(), stock_b_data.reset_index(),\n",
        "                                on=['year', 'month', 'day'], how='inner', suffixes=('_A', '_B'))\n",
        "        aligned_data['datetime'] = pd.to_datetime(aligned_data['year'].astype(str) + '-' +\n",
        "                                                  aligned_data['month'].astype(str) + '-' +\n",
        "                                                  aligned_data['day'].astype(str))\n",
        "        aligned_data = aligned_data.set_index('datetime').sort_index()\n",
        "\n",
        "        # Apply the lag to stock_b_data\n",
        "        lagged_stock_b_data = aligned_data['close_B'].shift(lag_days)\n",
        "\n",
        "        # Calculate correlation, dropping NaN values\n",
        "        correlation = aligned_data['close_A'].corr(lagged_stock_b_data)\n",
        "\n",
        "        # Store the correlation in the matrix\n",
        "        correlation_matrix.loc[ticker_a, ticker_b] = correlation\n",
        "\n",
        "  return correlation_matrix\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'stock_TimeFiltered_aggregated_close' is your aggregated stock data\n",
        "# and you want to calculate correlations ending on '2023-12-31' with a 1-day lag.\n",
        "# Replace 'stock_TimeFiltered_aggregated_close' with the actual name of your DataFrame.\n",
        "# end_date = '2023-12-31'\n",
        "# lagged_correlations = calculate_pairwise_lagged_correlation(stock_TimeFiltered_aggregated_close, end_date, lag_days=1)\n",
        "\n",
        "# Display the correlation matrix\n",
        "# print(lagged_correlations)\n",
        "\n",
        "# To access the correlation between specific stocks, e.g., GOOG and MSFT:\n",
        "# print(lagged_correlations.loc['GOOG', 'MSFT'])"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FtqUV9nKkT6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run Fucntions**"
      ],
      "metadata": {
        "id": "aCEfO-bsKNCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nasdaq_stocks = ImportStockData()\n",
        "# stock_TimeFiltered_aggregated_close = ManipulateStockData(nasdaq_stocks)\n",
        "# end_date = '2023-12-31'\n",
        "# lagged_correlations = calculate_lagged_correlation(stock_TimeFiltered_aggregated_close, end_date, lag_days=1)\n",
        "\n",
        "sixMonth_correlation_data = import_variable(\"6month_correlation_data.parquet\")"
      ],
      "metadata": {
        "id": "BxwPwW4fKQa3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}