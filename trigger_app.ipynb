{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYflA15lPVTZ3XnruR1s0g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBrWNkgEWPDj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import base64\n",
        "import json\n",
        "from flask import Flask\n",
        "\n",
        "# Be explicit with the auth imports to avoid attribute errors\n",
        "import google.auth\n",
        "from google.auth.transport import requests as google_auth_requests\n",
        "\n",
        "# Initialize the Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "PROJECT_ID = os.environ.get('GCP_PROJECT', 'robotic-fuze-463700-n5')\n",
        "TOPIC_ID = os.environ.get('PUBSUB_TOPIC', 'nightly-data-pull-topic')\n",
        "\n",
        "@app.route(\"/\", methods=[\"POST\"])\n",
        "def trigger_pipeline():\n",
        "    \"\"\"\n",
        "    Receives a POST request (from Cloud Scheduler) and publishes a\n",
        "    message to a Pub/Sub topic to start the data processing pipeline.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get the default credentials from the environment\n",
        "        credentials, project = google.auth.default(\n",
        "            scopes=[\"https://www.googleapis.com/auth/pubsub\"]\n",
        "        )\n",
        "\n",
        "        # Create a transport-specific request object using our explicit import\n",
        "        auth_req = google_auth_requests.Request()\n",
        "        credentials.refresh(auth_req)\n",
        "        token = credentials.token\n",
        "\n",
        "        # Construct the URL for the Pub/Sub REST API\n",
        "        url = f\"https://pubsub.googleapis.com/v1/projects/{PROJECT_ID}/topics/{TOPIC_ID}:publish\"\n",
        "\n",
        "        # The message can be simple, its presence is the trigger.\n",
        "        message_data = b'Start data pipeline'\n",
        "        base64_encoded_message = base64.b64encode(message_data).decode('utf-8')\n",
        "\n",
        "        # Construct the request body\n",
        "        payload = { \"messages\": [ { \"data\": base64_encoded_message } ] }\n",
        "\n",
        "        # Set the authorization header\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {token}\",\n",
        "            \"Content-Type\": \"application/json; charset=utf-8\"\n",
        "        }\n",
        "\n",
        "        # Make the POST request to the API\n",
        "        response = requests.post(url, data=json.dumps(payload), headers=headers)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        message_ids = response.json().get('messageIds', [])\n",
        "        print(f\"Published message(s) {message_ids} to {TOPIC_ID}.\")\n",
        "\n",
        "        return f\"Successfully triggered pipeline (Message IDs: {message_ids}).\", 202\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error publishing to Pub/Sub via REST API: {e}\")\n",
        "        return \"Error triggering pipeline.\", 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Get the port number from the environment variable PORT\n",
        "    port = int(os.environ.get(\"PORT\", 8080))\n",
        "    # Run the app, listening on all available network interfaces\n",
        "    app.run(debug=True, host=\"0.0.0.0\", port=port)\n"
      ]
    }
  ]
}